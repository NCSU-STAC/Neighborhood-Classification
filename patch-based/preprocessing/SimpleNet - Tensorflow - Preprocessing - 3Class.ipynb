{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training grid locations from gt10a.shp file and get corresponding band information for the patch from the raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756073.457553 1456685.87304 0.499284950117 0.499231422086\n",
      "Finished 100 points\n",
      "\n",
      "Finished 200 points\n",
      "\n",
      "Finished 300 points\n",
      "\n",
      "Finished 400 points\n",
      "\n",
      "Finished 500 points\n",
      "\n",
      "Finished 600 points\n",
      "\n",
      "Finished 700 points\n",
      "\n",
      "Finished 800 points\n",
      "\n",
      "Finished 900 points\n",
      "\n",
      "Finished 1000 points\n",
      "\n",
      "Finished 1100 points\n",
      "\n",
      "Finished 1200 points\n",
      "\n",
      "Finished 1300 points\n",
      "\n",
      "Finished 1400 points\n",
      "\n",
      "Finished 1500 points\n",
      "\n",
      "Finished 1600 points\n",
      "\n",
      "Finished 1700 points\n",
      "\n",
      "Finished 1800 points\n",
      "\n",
      "Finished 1900 points\n",
      "\n",
      "Finished 2000 points\n",
      "\n",
      "Finished 2100 points\n",
      "\n",
      "Finished 2200 points\n",
      "\n",
      "Finished 2300 points\n",
      "\n",
      "Finished 2400 points\n",
      "\n",
      "Finished 2500 points\n",
      "\n",
      "Finished 2600 points\n",
      "\n",
      "Finished 2700 points\n",
      "\n",
      "Finished 2800 points\n",
      "\n",
      "Finished 2900 points\n",
      "\n",
      "Finished 3000 points\n",
      "\n",
      "Finished 3100 points\n",
      "\n",
      "Finished 3200 points\n",
      "\n",
      "Finished 3300 points\n",
      "\n",
      "Finished 3400 points\n",
      "\n",
      "Finished 3500 points\n",
      "\n",
      "Finished 3600 points\n",
      "\n",
      "Finished 3700 points\n",
      "\n",
      "Finished 3800 points\n",
      "\n",
      "Finished 3900 points\n",
      "\n",
      "Finished 4000 points\n",
      "\n",
      "Finished 4100 points\n",
      "\n",
      "Finished 4200 points\n",
      "\n",
      "Finished 4300 points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona, random\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#rasterFileName = \"/home/gadiraju/data/bl-slums/raw-img/MUL_mosaic_415.tif\" #path to raster\n",
    "rasterFileName1 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_415.tif\"\n",
    "dataset1 = gdal.Open(rasterFileName1)\n",
    "rasterFileName2 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_415_NDBI.tif\"\n",
    "dataset2 = gdal.Open(rasterFileName2)\n",
    "rasterFileName3 = \"/scratch/slums/bl-slums/features/pan/haralick/PAN_mosaic_415-simple-50.tif\"\n",
    "dataset3 = gdal.Open(rasterFileName3)\n",
    "rasterFileName4 = \"/scratch/slums/bl-slums/raw-img/PAN_mosaic_415_edgeDensity.tif\"\n",
    "dataset4 = gdal.Open(rasterFileName4)\n",
    "vector = fiona.open('/scratch/slums/bl-slums/gt/final-data/gt10e/gt10e.shp')\n",
    "imggeotrans = dataset1.GetGeoTransform()\n",
    "coordinates_list = []\n",
    "count_numbers = [0]*3\n",
    "#print count_numbers\n",
    "actual_class = []\n",
    "train_test = []\n",
    "ids_list = []\n",
    "for feat in vector:\n",
    "    curr_class = feat['properties']['Cl']\n",
    "    if curr_class >0:\n",
    "        #print curr_class\n",
    "        coordinates_list.append(feat['geometry']['coordinates'])\n",
    "        count_numbers[curr_class-1]+=1\n",
    "        actual_class.append(curr_class)\n",
    "        train_test.append(feat['properties']['Type'])\n",
    "        ids_list.append(feat['properties']['ID'])\n",
    "bands1=[]\n",
    "bands2=[]\n",
    "bands3=[]\n",
    "bands4=[]\n",
    "data_all_bands = []\n",
    "cols = dataset1.RasterXSize\n",
    "rows = dataset1.RasterYSize\n",
    "\n",
    "transform = dataset1.GetGeoTransform()\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "print xOrigin, yOrigin, pixelWidth, pixelHeight\n",
    "\n",
    "for i in range(8):\n",
    "    bands1.append(dataset1.GetRasterBand(i+1)) \n",
    "    # data_all_bands.append(band.ReadAsArray(0,0,cols,rows).astype(np.float))\n",
    "bands2.append(dataset2.GetRasterBand(1))\n",
    "for i in range(8):\n",
    "    bands3.append(dataset3.GetRasterBand(i+1))\n",
    "bands4.append(dataset4.GetRasterBand(1))\n",
    "points_list = coordinates_list #list of X,Y coordinates\n",
    "\n",
    "#points_list = [(756073.458902 , 1456683.91481)]\n",
    "train_images_list = [[],[],[]]\n",
    "test_images_list = [[],[],[]]\n",
    "test_IDs = []\n",
    "for pt in range(len(points_list)):\n",
    "    if pt%100 == 0 and pt>0:\n",
    "        print 'Finished {} points\\n'.format(pt)\n",
    "    point = points_list[pt]\n",
    "    cls = actual_class[pt]\n",
    "    #print point, cls\n",
    "    curr = np.zeros((18,40,40))-1\n",
    "    curr = curr.astype(float)\n",
    "    col = int((point[0] - xOrigin) / pixelWidth)\n",
    "    row = int((yOrigin - point[1] ) / pixelHeight)\n",
    "    for k in range(8):\n",
    "        data = bands1[k].ReadAsArray(col,row,40,40).astype(np.float)\n",
    "        #print data[9,9]\n",
    "        curr[k,:,:] = data\n",
    "    data = bands2[0].ReadAsArray(col,row,40,40).astype(np.float)\n",
    "    curr[8,:,:] = data\n",
    "    for k in range(8):\n",
    "        data = bands3[k].ReadAsArray(col,row,40,40).astype(np.float)\n",
    "        #print data[9,9]\n",
    "        curr[9+k,:,:] = data\n",
    "    data = bands4[0].ReadAsArray(col,row,40,40).astype(np.float)\n",
    "    curr[17,:,:] = data\n",
    "    curr = curr.T\n",
    "    if train_test[pt] == 1:\n",
    "        train_images_list[cls-1].append(curr)\n",
    "    else:\n",
    "        test_images_list[cls-1].append(curr) \n",
    "        test_IDs.append(ids_list[pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr_train shape =(1014, 40, 40, 18)\n",
      "(1014, 40, 40, 18) (235, 40, 40, 18)\n",
      "(235, 40, 40, 18)\n",
      "(1014, 40, 40, 18) (1014, 3) (235, 40, 40, 18) (235, 3)\n",
      "Curr_train shape =(1242, 40, 40, 18)\n",
      "(1242, 40, 40, 18) (202, 40, 40, 18)\n",
      "(202, 40, 40, 18)\n",
      "Curr_train shape =(1291, 40, 40, 18)\n",
      "(1291, 40, 40, 18) (342, 40, 40, 18)\n",
      "(342, 40, 40, 18)\n",
      "(3547, 40, 40, 18) (3547, 3) (779, 40, 40, 18) (779, 3)\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(train_images_list)):\n",
    "    tmp_Y_1 = np.zeros((len(train_images_list[k]),len(train_images_list)))\n",
    "    #print tmp_Y_1.shape\n",
    "    tmp_Y_1[:,k] = 1\n",
    "    tmp_Y_2 = np.zeros((len(test_images_list[k]),len(test_images_list)))\n",
    "    tmp_Y_2[:,k] = 1\n",
    "    curr_train = train_images_list[k]\n",
    "    curr_train = np.asarray(curr_train)\n",
    "    print 'Curr_train shape ={}'.format(curr_train.shape)\n",
    "    curr_test = np.asarray(test_images_list[k])\n",
    "    print curr_train.shape, curr_test.shape\n",
    "    print curr_test.shape\n",
    "    if k==0:\n",
    "        trainX = curr_train\n",
    "        testX = curr_test\n",
    "        trainY = tmp_Y_1\n",
    "        testY = tmp_Y_2\n",
    "        print trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "    else:\n",
    "        trainX = np.vstack((trainX, curr_train))\n",
    "        testX = np.vstack((testX, curr_test))\n",
    "        trainY = np.vstack((trainY, tmp_Y_1))\n",
    "        testY = np.vstack((testY, tmp_Y_2))\n",
    "\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the above files to disk so that we don't need to re-create them many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/final-pt-tr-3-X','w')\n",
    "pickle.dump(trainX,f)\n",
    "f.close()\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/final-pt-tr-3-Y','w')\n",
    "pickle.dump(trainY,f)\n",
    "f.close()\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/final-pt-te-3-X','w')\n",
    "pickle.dump(testX,f)\n",
    "f.close()\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/final-pt-te-3-Y','w')\n",
    "pickle.dump(testY,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
