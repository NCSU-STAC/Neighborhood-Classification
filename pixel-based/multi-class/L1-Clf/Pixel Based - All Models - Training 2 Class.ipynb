{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Read files \n",
    "trainX = np.load('/scratch/slums/bl-slums/gt/final-px-tr-2-Xa')\n",
    "trainY = np.load('/scratch/slums/bl-slums/gt/final-px-tr-2-Ya')\n",
    "testX = np.load('/scratch/slums/bl-slums/gt/final-px-te-2-Xa')\n",
    "testY = np.load('/scratch/slums/bl-slums/gt/final-px-te-2-Ya')\n",
    "\n",
    "trainY = trainY.ravel()\n",
    "testY = testY.ravel()\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "# Source: scikit-learn tutorials\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "model = xgboost.XGBClassifier(nthread=16 ,objective='binary:logistic')\n",
    "learning_rate = [0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "n_estimators = [1000,5000,6000, 7000, 10000]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators = n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "#kfold = StratifiedKFold(n_splits = 10, random_state=7)\n",
    "xgb = xgboost.XGBClassifier(max_depth=500, n_estimators=1000, nthread=8 , objective='binary:logistic', learning_rate = 0.7 )\n",
    "#results = cross_val_score(xgb, trainX, trainY, cv=kfold)\n",
    "#print(results)\n",
    "xgb.fit(trainX,trainY)\n",
    "result = xgb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-xgboost-2-Cl-model.sav'\n",
    "pickle.dump(xgb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [2, 3],\n",
    "              \"min_samples_leaf\": [1, 3],\n",
    "              \"n_estimators\": [500, 1000],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search = GridSearchCV(rf, param_grid = param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, bootstrap = False, min_samples_leaf = 1, min_samples_split = 2, max_depth = None)\n",
    "rf.fit(trainX,trainY)\n",
    "result = rf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "fname = 'VHR-rf-2-Cl-model.sav'\n",
    "pickle.dump(rf, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX,trainY)\n",
    "result = nb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-gnb-2-Cl-model.sav'\n",
    "pickle.dump(nb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(trainX,trainY)\n",
    "result = dt.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-dt-2-Cl-model.sav'\n",
    "pickle.dump(dt, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv = StratifiedKFold(n_splits = 10, random_state =7 )\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = list(np.arange(3,11,1))\n",
    "#print n_neighs\n",
    "params_grid = dict(n_neighbors= n_neighbors)\n",
    "knn_grid_search = GridSearchCV(estimator = knn, n_jobs = -1, param_grid = params_grid)\n",
    "knn_grid_result = knn_grid_search.fit(trainX, trainY)\n",
    "report(knn_grid_result.cv_results_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(trainX, trainY)\n",
    "result= knn.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-knn-2-Cl-model.sav'\n",
    "pickle.dump(knn, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "params_grid={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100,100,100)],\n",
    "'alpha': [0.0001, 0.00001, 0.01],\n",
    "'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}\n",
    "\n",
    "mlp_grid_search = GridSearchCV(estimator=mlp,param_grid=params_grid,n_jobs=-1,cv=kfold)\n",
    "mlp_grid_result = mlp_grid_search.fit(trainX, trainY)\n",
    "report(mlp_grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation='logistic', learning_rate = 'constant',hidden_layer_sizes=(100, 100, 100, 100), alpha = 0.00001)\n",
    "mlp.fit(trainX, trainY)\n",
    "result = mlp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-mlp-2-Cl-model.sav'\n",
    "pickle.dump(mlp, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABOOST\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "adb = AdaBoostClassifier()\n",
    "params_grid = dict(n_estimators=[50,100,500,1000,5000], learning_rate=[0.01, 0.007, 0.0001, 0.1, 0.0007])\n",
    "adb_grid_search = GridSearchCV(estimator=adb, param_grid = params_grid, cv=kfold)\n",
    "adb_search_result = adb_grid_search.fit(trainX, trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(adb_search_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "adb = AdaBoostClassifier(n_estimators=500, learning_rate=0.1)\n",
    "adb.fit(trainX, trainY)\n",
    "result = adb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-adaboost-2-Cl-model.sav'\n",
    "pickle.dump(adb, open(fname, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
