{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3547, 18) (3547,) (779, 18) (779,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/unity.ncsu.edu/users/k/kgadira/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnTestSlums = np.sum(testY==0)\\n\\n# print nTestSlums\\n# Pick all other attributes in number equal to nTestSlums randomly\\nclass0Indices = np.where(testY==0)\\nclass1Indices = np.where(testY==1)\\nclass2Indices = np.where(testY==2)\\n\\nprint len(class1Indices[0])\\nindices1 = class1Indices[0][np.random.choice(len(class1Indices[0]), nTestSlums)]\\nindices2 = class2Indices[0][np.random.choice(len(class2Indices[0]), nTestSlums)]\\n\\nclass0X = testX[class0Indices[0],:]\\nclass1X = testX[indices1,:]\\nclass2X = testX[indices2,:]\\n\\nprint class0X.shape, class1X.shape, class2X.shape\\nclass0Y = testY[class0Indices]\\nclass1Y = testY[indices1]\\nclass2Y = testY[indices2]\\n\\ntestX = np.vstack((class0X, class1X, class2X))\\ntestY = np.hstack((class0Y, class1Y, class2Y))\\n\\nprint testX.shape, testY.shape\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Read files \n",
    "trainX = np.load('/scratch/slums/bl-slums/gt/final-px-tr-2-Xa')\n",
    "trainY = np.load('/scratch/slums/bl-slums/gt/final-px-tr-2-Ya')\n",
    "testX = np.load('/scratch/slums/bl-slums/gt/final-px-te-2-Xa')\n",
    "testY = np.load('/scratch/slums/bl-slums/gt/final-px-te-2-Ya')\n",
    "\n",
    "trainY = trainY.ravel()\n",
    "testY = testY.ravel()\n",
    "# Reshape training and test data to be suitable to sklearn methods\n",
    "#print trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "#trainX = trainX.reshape(trainX.shape[0], trainX.shape[2])\n",
    "#valX = valX.reshape(valX.shape[0], valX.shape[2])\n",
    "#testX = testX.reshape(testX.shape[0], testX.shape[2])\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "\n",
    "'''\n",
    "nTestSlums = np.sum(testY==0)\n",
    "\n",
    "# print nTestSlums\n",
    "# Pick all other attributes in number equal to nTestSlums randomly\n",
    "class0Indices = np.where(testY==0)\n",
    "class1Indices = np.where(testY==1)\n",
    "class2Indices = np.where(testY==2)\n",
    "\n",
    "print len(class1Indices[0])\n",
    "indices1 = class1Indices[0][np.random.choice(len(class1Indices[0]), nTestSlums)]\n",
    "indices2 = class2Indices[0][np.random.choice(len(class2Indices[0]), nTestSlums)]\n",
    "\n",
    "class0X = testX[class0Indices[0],:]\n",
    "class1X = testX[indices1,:]\n",
    "class2X = testX[indices2,:]\n",
    "\n",
    "print class0X.shape, class1X.shape, class2X.shape\n",
    "class0Y = testY[class0Indices]\n",
    "class1Y = testY[indices1]\n",
    "class2Y = testY[indices2]\n",
    "\n",
    "testX = np.vstack((class0X, class1X, class2X))\n",
    "testY = np.hstack((class0Y, class1Y, class2Y))\n",
    "\n",
    "print testX.shape, testY.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier\n",
    "\n",
    "# Run the next cell only if you want to use a subset of the 17 features generated:\n",
    "8 Pansharpened (0-7)\n",
    "8 Haralick (8-15)\n",
    "1 NDBI (16)\n",
    "1 Edge Density (17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)\n",
    "\n",
    "# trainX = trainX[:,0:7]\n",
    "# testX = testX[:,0:7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256\n",
      "1291\n",
      "[ 34.98723957   0.          47.76380179  56.55156252  53.67838531\n",
      "  32.02109385  42.76119783  53.41276031  38.26328119  50.07916684\n",
      "  40.857552    46.73229165  56.04244773  49.41953097  41.73411454\n",
      "  40.22890621  52.04921881  38.29427094  37.10781246  45.15182294\n",
      "  26.53151041  46.84296852  10.54088532  22.57812468  33.74322912\n",
      "   4.50677086  26.4473958    0.           0.           0.          47.69739585\n",
      "  45.81588544  28.38203123  34.66848956  48.87057273  38.42708323\n",
      "  47.19713529  36.00989607  38.3473959   33.52187501  48.67578136\n",
      "  40.05624983  51.38958348  51.63749992  46.79869779  38.56875006\n",
      "  45.33776029  36.50572936  50.67682298  39.05572923  39.10000017\n",
      "  47.94088544  42.10598988  46.71015644  42.41145823  31.49869802\n",
      "  57.80885442  49.02994802  47.67968718  39.62239615  54.39557298\n",
      "  48.48541662  27.10260434   5.6666667    6.43255209  34.51354165\n",
      "  31.39687475   0.          38.59973929  19.51015637  27.9083333\n",
      "  19.29322918   0.           0.           0.           0.          37.16536469\n",
      "  39.37005213   0.          51.55781248  42.82760419  38.65286435\n",
      "  49.97734398  46.17890665  48.85729165  54.2583331   44.40364583   0.\n",
      "  30.97187487  48.26406235  32.56562498  39.92786471  37.31588491\n",
      "  53.0630206   45.26250013   0.           0.          42.08828121\n",
      "  61.38593758]\n"
     ]
    }
   ],
   "source": [
    "print np.sum(trainY == 0)\n",
    "print np.sum(trainY == 1)\n",
    "print trainX[1:100,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.024 (std: 0.012)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.024 (std: 0.011)\n",
      "Parameters: {'n_estimators': 10000, 'learning_rate': 0.7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.024 (std: 0.011)\n",
      "Parameters: {'n_estimators': 7000, 'learning_rate': 0.7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "model = xgboost.XGBClassifier(nthread=16 ,objective='binary:logistic')\n",
    "learning_rate = [0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "n_estimators = [1000,5000,6000, 7000, 10000]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators = n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.991014120668\n",
      "\n",
      "Confusion Matrix \n",
      " [[436   1]\n",
      " [  6 336]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.99      1.00      0.99       437\n",
      "      Other       1.00      0.98      0.99       342\n",
      "\n",
      "avg / total       0.99      0.99      0.99       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "#kfold = StratifiedKFold(n_splits = 10, random_state=7)\n",
    "xgb = xgboost.XGBClassifier(max_depth=500, n_estimators=1000, nthread=8 , objective='binary:logistic', learning_rate = 0.7 )\n",
    "#results = cross_val_score(xgb, trainX, trainY, cv=kfold)\n",
    "#print(results)\n",
    "xgb.fit(trainX,trainY)\n",
    "result = xgb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-xgboost-2-Cl-model.sav'\n",
    "pickle.dump(xgb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.025 (std: 0.005)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 500, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.025 (std: 0.005)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 500, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.026 (std: 0.005)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "#kfold = KFold(n_splits = 10, random_state=100)\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "#results = cross_val_score(rf,trainX, trainY, cv=kfold)\n",
    "#print results.mean(), results.std()\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [2, 3],\n",
    "              \"min_samples_leaf\": [1, 3],\n",
    "              \"n_estimators\": [500, 1000],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search = GridSearchCV(rf, param_grid = param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.98459563543\n",
      "\n",
      "Confusion Matrix \n",
      " [[435   2]\n",
      " [ 10 332]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.98      1.00      0.99       437\n",
      "      Other       0.99      0.97      0.98       342\n",
      "\n",
      "avg / total       0.98      0.98      0.98       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, bootstrap = False, min_samples_leaf = 1, min_samples_split = 2, max_depth = None)\n",
    "rf.fit(trainX,trainY)\n",
    "result = rf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "fname = 'VHR-rf-2-Cl-model.sav'\n",
    "pickle.dump(rf, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.962772785623\n",
      "\n",
      "Confusion Matrix \n",
      " [[430   7]\n",
      " [ 22 320]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.95      0.98      0.97       437\n",
      "      Other       0.98      0.94      0.96       342\n",
      "\n",
      "avg / total       0.96      0.96      0.96       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX,trainY)\n",
    "result = nb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-gnb-2-Cl-model.sav'\n",
    "pickle.dump(nb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.982028241335\n",
      "\n",
      "Confusion Matrix \n",
      " [[434   3]\n",
      " [ 11 331]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.98      0.99      0.98       437\n",
      "      Other       0.99      0.97      0.98       342\n",
      "\n",
      "avg / total       0.98      0.98      0.98       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(trainX,trainY)\n",
    "result = dt.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-dt-2-Cl-model.sav'\n",
    "pickle.dump(dt, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.920 (std: 0.092)\n",
      "Parameters: {'n_neighbors': 4}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.919 (std: 0.090)\n",
      "Parameters: {'n_neighbors': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.919 (std: 0.089)\n",
      "Parameters: {'n_neighbors': 5}\n",
      "\n",
      "Overall accuracy = 0.970474967908\n",
      "\n",
      "Confusion Matrix \n",
      " [[425  12]\n",
      " [ 11 331]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.97      0.97      0.97       437\n",
      "      Other       0.97      0.97      0.97       342\n",
      "\n",
      "avg / total       0.97      0.97      0.97       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv = StratifiedKFold(n_splits = 10, random_state =7 )\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = list(np.arange(3,11,1))\n",
    "#print n_neighs\n",
    "params_grid = dict(n_neighbors= n_neighbors)\n",
    "knn_grid_search = GridSearchCV(estimator = knn, n_jobs = -1, param_grid = params_grid)\n",
    "knn_grid_result = knn_grid_search.fit(trainX, trainY)\n",
    "report(knn_grid_result.cv_results_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(trainX, trainY)\n",
    "result= knn.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-knn-2-Cl-model.sav'\n",
    "pickle.dump(knn, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svmclf = SVC(gamma=2,C=0.5)\n",
    "svmclf.fit(trainX, trainY)\n",
    "result = svmclf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','BG'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.005)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.984 (std: 0.007)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.984 (std: 0.007)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.984 (std: 0.008)\n",
      "Parameters: {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "params_grid={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100,100,100)],\n",
    "'alpha': [0.0001, 0.00001, 0.01],\n",
    "'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}\n",
    "\n",
    "mlp_grid_search = GridSearchCV(estimator=mlp,param_grid=params_grid,n_jobs=-1,cv=kfold)\n",
    "mlp_grid_result = mlp_grid_search.fit(trainX, trainY)\n",
    "report(mlp_grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.978177150193\n",
      "\n",
      "Confusion Matrix \n",
      " [[432   5]\n",
      " [ 12 330]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.97      0.99      0.98       437\n",
      "      Other       0.99      0.96      0.97       342\n",
      "\n",
      "avg / total       0.98      0.98      0.98       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic', learning_rate = 'constant',hidden_layer_sizes=(100, 100, 100, 100), alpha = 0.00001)\n",
    "mlp.fit(trainX, trainY)\n",
    "result = mlp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-mlp-2-Cl-model.sav'\n",
    "pickle.dump(mlp, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "gp = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "gp.fit(trainX, trainY)\n",
    "result = gp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Slum','Urban','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a29ac7e5ca84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0madb_grid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0madb_search_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madb_grid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madb_search_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "adb = AdaBoostClassifier()\n",
    "params_grid = dict(n_estimators=[50,100,500,1000,5000], learning_rate=[0.01, 0.007, 0.0001, 0.1, 0.0007])\n",
    "adb_grid_search = GridSearchCV(estimator=adb, param_grid = params_grid, cv=kfold)\n",
    "adb_search_result = adb_grid_search.fit(trainX, trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.994 (std: 0.003)\n",
      "Parameters: {'n_estimators': 500, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.994 (std: 0.003)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.993 (std: 0.003)\n",
      "Parameters: {'n_estimators': 5000, 'learning_rate': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(adb_search_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.992297817715\n",
      "\n",
      "Confusion Matrix \n",
      " [[436   1]\n",
      " [  5 337]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.99      1.00      0.99       437\n",
      "      Other       1.00      0.99      0.99       342\n",
      "\n",
      "avg / total       0.99      0.99      0.99       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "adb = AdaBoostClassifier(n_estimators=500, learning_rate=0.1)\n",
    "adb.fit(trainX, trainY)\n",
    "result = adb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-adaboost-2-Cl-model.sav'\n",
    "pickle.dump(adb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [xgb, rf, nb, dt, knn, mlp, adb]\n",
    "clf-names = ['xgb', 'rf', 'nb', 'dt', 'knn', 'mlp', 'adb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "rasterFileName1 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_415.tif\"\n",
    "dataset1 = gdal.Open(rasterFileName1)\n",
    "rasterFileName2 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_415_NDBI.tif\"\n",
    "dataset2 = gdal.Open(rasterFileName2)\n",
    "rasterFileName3 = \"/scratch/slums/bl-slums/features/pan/haralick/PAN_mosaic_415-simple-50.tif\"\n",
    "dataset3 = gdal.Open(rasterFileName3)\n",
    "rasterFileName4 = \"/scratch/slums/bl-slums/raw-img/PAN_mosaic_415_edgeDensity.tif\"\n",
    "dataset4 = gdal.Open(rasterFileName4)\n",
    "\n",
    "\n",
    "imggeotrans = dataset1.GetGeoTransform()\n",
    "\n",
    "\n",
    "bands1=[]\n",
    "bands2=[]\n",
    "bands3=[]\n",
    "bands4=[]\n",
    "data_all_bands = []\n",
    "cols = dataset1.RasterXSize\n",
    "rows = dataset1.RasterYSize\n",
    "\n",
    "transform = dataset1.GetGeoTransform()\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "print xOrigin, yOrigin, pixelWidth, pixelHeight\n",
    "\n",
    "for i in range(8):\n",
    "    bands1.append(dataset1.GetRasterBand(i+1)) \n",
    "    # data_all_bands.append(band.ReadAsArray(0,0,cols,rows).astype(np.float))\n",
    "bands2.append(dataset2.GetRasterBand(1)) \n",
    "for i in range(8):\n",
    "    bands3.append(dataset3.GetRasterBand(i+1)) \n",
    "bands4.append(dataset4.GetRasterBand(1)) \n",
    "\n",
    "#all_data = np.zeros((rows, cols, 18))\n",
    "#for k in range(8):\n",
    "#    all_data[:,:,k] = bands1[k].ReadAsArray(0,0,cols, rows)\n",
    "    \n",
    "#for k in range(8):\n",
    "#    all_data[:,:,k+8] = bands3[k].ReadAsArray(0,0,cols, rows)\n",
    "#all_data[:,:,16] = bands2[0].ReadAsArray(0,0,cols, rows)\n",
    "#all_data[:,:,17] = bands4[0].ReadAsArray(0,0,cols, rows)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import time\n",
    "start_t = time.time()\n",
    "result_raster = np.zeros((rows,cols))-1\n",
    "noneData = False\n",
    "for i in range(rows):\n",
    "    curr_row = all_data[i,:,:]\n",
    "    result = rf.predict(curr_row)    \n",
    "    result_raster[i,:] = result\n",
    "    if i%10 ==0:\n",
    "        print '{} rows completed'.format(i)\n",
    "        \n",
    "end_t = time.time()\n",
    "\n",
    "print 'Total exec time = {}'.format(end_t-start_t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import time\n",
    "start_t = time.time()\n",
    "result_raster = np.zeros((rows,cols), dtype=np.int)-1\n",
    "noneData = False\n",
    "for i in range(rows):\n",
    "    if i%100==0:\n",
    "        print 'Finished {} pixels'.format(i)\n",
    "    curr_row = np.zeros((cols,18))-1\n",
    "    for k in range(8):\n",
    "        data = bands1[k].ReadAsArray(0,i,cols,1)\n",
    "        data =data.astype(np.float)\n",
    "        print data.shape\n",
    "        curr_row[:,k] = data \n",
    "    for k in range(8):\n",
    "        data = bands3[k].ReadAsArray(0,i,cols,1)\n",
    "        print data.shape\n",
    "        data = data.astype(np.float)\n",
    "        curr_row[:,k+8] = data \n",
    "    data = bands2[0].ReadAsArray(0,i,cols,1)\n",
    "    curr_row[:,16] = data\n",
    "    data = bands4[0].ReadAsArray(0,i,cols,1)\n",
    "    curr_row[:,17] = data\n",
    "    #print curr_row.shape\n",
    "    #result = rf.predict(curr_row)    \n",
    "    #result_raster[i,:] = result\n",
    "        \n",
    "end_t = time.time()\n",
    "\n",
    "print 'Total exec time = {}'.format(end_t-start_t)\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from utils import io\n",
    "\n",
    "io.write_image(cols, rows, 1,imggeotrans, result_raster, '/scratch/slums/bl-slums/clf-img/clf-xgboost-building.tif')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
