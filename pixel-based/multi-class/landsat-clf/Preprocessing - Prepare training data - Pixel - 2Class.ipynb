{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#rasterFileName = \"/home/gadiraju/data/bl-slums/raw-img/MUL_mosaic_415.tif\" #path to raster\n",
    "rasterFileName1 = \"/scratch/slums/bl-slums/raw-img/landsat7/PS-feb-2002-extract.tif\"\n",
    "dataset1 = gdal.Open(rasterFileName1)\n",
    "rasterFileName2 = \"/scratch/slums/bl-slums/raw-img/landsat7/ETM-feb-2002-extract-NDBI.tif\"\n",
    "dataset2 = gdal.Open(rasterFileName2)\n",
    "rasterFileName3 = \"/scratch/slums/bl-slums/raw-img/landsat7/simple-feb-2002-extract.tif\"\n",
    "dataset3 = gdal.Open(rasterFileName3)\n",
    "rasterFileName4 = \"/scratch/slums/bl-slums/raw-img/landsat7/adv-feb-2002-extract.tif\"\n",
    "dataset4 = gdal.Open(rasterFileName4)\n",
    "rasterFileName5 = \"/scratch/slums/bl-slums/raw-img/landsat7/higher-feb-2002-extract.tif\"\n",
    "dataset5 = gdal.Open(rasterFileName5)\n",
    "vector = fiona.open('/scratch/slums/bl-slums/gt/final-data/landsat-final/gt10e/gt10e.shp')\n",
    "imggeotrans1 = dataset1.GetGeoTransform()\n",
    "coordinates_list = []\n",
    "count_numbers = [0]*2\n",
    "train_or_test = []\n",
    "#print count_numbers\n",
    "actual_class = []\n",
    "for feat in vector:\n",
    "    curr_class = feat['properties']['ULabel']\n",
    "    \n",
    "    if curr_class >0:\n",
    "        #print curr_class\n",
    "        #print curr_class\n",
    "        train_or_test.append(feat['properties']['Type'])\n",
    "        coordinates_list.append(feat['geometry']['coordinates'])\n",
    "        #count_numbers[curr_class-1]+=1\n",
    "        actual_class.append(curr_class)\n",
    "\n",
    "bands1=[]\n",
    "bands2=[]\n",
    "bands3=[]\n",
    "bands4=[]\n",
    "bands5=[]\n",
    "data_all_bands = []\n",
    "cols = dataset1.RasterXSize\n",
    "rows = dataset1.RasterYSize\n",
    "\n",
    "transform = dataset1.GetGeoTransform()\n",
    "\n",
    "imggeotrans2 = dataset2.GetGeoTransform()\n",
    "imggeotrans3 = dataset3.GetGeoTransform()\n",
    "\n",
    "\n",
    "print '{} \\n +++++++++++++++++++++++++++ \\n {} \\n {}'.format(imggeotrans1, imggeotrans2, imggeotrans3)\n",
    "\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "print xOrigin, yOrigin, pixelWidth, pixelHeight\n",
    "\n",
    "for i in range(6):\n",
    "    bands1.append(dataset1.GetRasterBand(i+1)) \n",
    "    # data_all_bands.append(band.ReadAsArray(0,0,cols,rows).astype(np.float))\n",
    "bands2.append(dataset2.GetRasterBand(1))\n",
    "for i in range(8):#simple\n",
    "    bands3.append(dataset3.GetRasterBand(i+1)) \n",
    "for i in range(10):#adv\n",
    "    bands4.append(dataset4.GetRasterBand(i+1)) \n",
    "for i in range(11):#higher\n",
    "    bands5.append(dataset5.GetRasterBand(i+1)) \n",
    "points_list = coordinates_list #list of X,Y coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 points\n",
      "\n",
      "Finished 500 points\n",
      "\n",
      "Finished 1000 points\n",
      "\n",
      "Finished 1500 points\n",
      "\n",
      "Finished 2000 points\n",
      "\n",
      "Finished 2500 points\n",
      "\n",
      "1196 1125 242 282\n"
     ]
    }
   ],
   "source": [
    "#points_list = [(756073.458902 , 1456683.91481)]\n",
    "train_images_list = [[],[]]\n",
    "test_images_list = [[],[]]\n",
    "coords_list = [[],[]]\n",
    "for pt in range(len(points_list)):\n",
    "    if pt%500 == 0:\n",
    "        print 'Finished {} points\\n'.format(pt)\n",
    "    point = points_list[pt]\n",
    "    cls = actual_class[pt]\n",
    "    #print point, cls\n",
    "    curr = np.zeros((1,36))-1\n",
    "    curr = curr.astype(float)\n",
    "    col = int((point[0] - xOrigin) / pixelWidth)\n",
    "    row = int((yOrigin - point[1] ) / pixelHeight)\n",
    "    for k in range(6):\n",
    "        data = bands1[k].ReadAsArray(col,row,1,1).astype(np.float)\n",
    "        #print point[0], point[1], data\n",
    "        curr[0,k] = data\n",
    "    data = bands2[0].ReadAsArray(col,row,1,1).astype(np.float)\n",
    "    curr[0,6] = data\n",
    "    for k in range(8):\n",
    "        data = bands3[k].ReadAsArray(col,row,1,1).astype(np.float)\n",
    "        curr[0,7+k] = data \n",
    "    for k in range(10):\n",
    "        data = bands4[k].ReadAsArray(col,row,1,1).astype(np.float)\n",
    "        curr[0,15+k] = data\n",
    "    for k in range(11):\n",
    "        data = bands5[k].ReadAsArray(col,row,1,1).astype(np.float)\n",
    "        curr[0,25+k] = data\n",
    "    if train_or_test[pt] == 1:\n",
    "        train_images_list[cls-1].append(curr)\n",
    "    else:\n",
    "        test_images_list[cls-1].append(curr)\n",
    "        \n",
    "print len(train_images_list[0]), len(train_images_list[1]), len(test_images_list[0]), len(test_images_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n",
      "242\n",
      "1125\n",
      "282\n",
      "(2321, 36) (2321, 1) (524, 36) (524, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    curr_train_imgs = train_images_list[i]\n",
    "    n_train_images = len(curr_train_imgs)\n",
    "    print n_train_images\n",
    "    curr_test_imgs = test_images_list[i]\n",
    "    n_test_images = len(curr_test_imgs)\n",
    "    print n_test_images\n",
    "    curr_train_y = np.zeros((n_train_images, 1))+i\n",
    "    curr_test_y = np.zeros((n_test_images, 1))+i\n",
    "    if i == 0:\n",
    "        trainX = np.asarray(curr_train_imgs)\n",
    "        trainY = curr_train_y\n",
    "        testX = np.asarray(curr_test_imgs)\n",
    "        testY = curr_test_y\n",
    "        \n",
    "    else:\n",
    "        trainX = np.vstack((trainX, curr_train_imgs))\n",
    "        trainY = np.vstack((trainY, curr_train_y))\n",
    "        testX = np.vstack((testX, curr_test_imgs))\n",
    "        testY = np.vstack((testY, curr_test_y))\n",
    "\n",
    "trainX = trainX.reshape(trainX.shape[0],trainX.shape[2])\n",
    "testX = testX.reshape(testX.shape[0], testX.shape[2])\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/LS-final-px-tr-2-Xa','w')\n",
    "pickle.dump(trainX,f)\n",
    "f.close()\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/LS-final-px-tr-2-Ya','w')\n",
    "pickle.dump(trainY,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/LS-final-px-te-2-Xa','w')\n",
    "pickle.dump(testX,f)\n",
    "f.close()\n",
    "\n",
    "f = open('/scratch/slums/bl-slums/gt/LS-final-px-te-2-Ya','w')\n",
    "pickle.dump(testY,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
