{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2321, 36) (2321,) (524, 36) (524,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/unity.ncsu.edu/users/k/kgadira/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnTestSlums = np.sum(testY==0)\\n\\n# print nTestSlums\\n# Pick all other attributes in number equal to nTestSlums randomly\\nclass0Indices = np.where(testY==0)\\nclass1Indices = np.where(testY==1)\\nclass2Indices = np.where(testY==2)\\n\\nprint len(class1Indices[0])\\nindices1 = class1Indices[0][np.random.choice(len(class1Indices[0]), nTestSlums)]\\nindices2 = class2Indices[0][np.random.choice(len(class2Indices[0]), nTestSlums)]\\n\\nclass0X = testX[class0Indices[0],:]\\nclass1X = testX[indices1,:]\\nclass2X = testX[indices2,:]\\n\\nprint class0X.shape, class1X.shape, class2X.shape\\nclass0Y = testY[class0Indices]\\nclass1Y = testY[indices1]\\nclass2Y = testY[indices2]\\n\\ntestX = np.vstack((class0X, class1X, class2X))\\ntestY = np.hstack((class0Y, class1Y, class2Y))\\n\\nprint testX.shape, testY.shape\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Read files \n",
    "trainX = np.load('/scratch/slums/bl-slums/gt/LS-final-px-tr-2-Xa')\n",
    "trainY = np.load('/scratch/slums/bl-slums/gt/LS-final-px-tr-2-Ya')\n",
    "testX = np.load('/scratch/slums/bl-slums/gt/LS-final-px-te-2-Xa')\n",
    "testY = np.load('/scratch/slums/bl-slums/gt/LS-final-px-te-2-Ya')\n",
    "\n",
    "trainY = trainY.ravel()\n",
    "testY = testY.ravel()\n",
    "# Reshape training and test data to be suitable to sklearn methods\n",
    "#print trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "#trainX = trainX.reshape(trainX.shape[0], trainX.shape[2])\n",
    "#valX = valX.reshape(valX.shape[0], valX.shape[2])\n",
    "#testX = testX.reshape(testX.shape[0], testX.shape[2])\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "\n",
    "'''\n",
    "nTestSlums = np.sum(testY==0)\n",
    "\n",
    "# print nTestSlums\n",
    "# Pick all other attributes in number equal to nTestSlums randomly\n",
    "class0Indices = np.where(testY==0)\n",
    "class1Indices = np.where(testY==1)\n",
    "class2Indices = np.where(testY==2)\n",
    "\n",
    "print len(class1Indices[0])\n",
    "indices1 = class1Indices[0][np.random.choice(len(class1Indices[0]), nTestSlums)]\n",
    "indices2 = class2Indices[0][np.random.choice(len(class2Indices[0]), nTestSlums)]\n",
    "\n",
    "class0X = testX[class0Indices[0],:]\n",
    "class1X = testX[indices1,:]\n",
    "class2X = testX[indices2,:]\n",
    "\n",
    "print class0X.shape, class1X.shape, class2X.shape\n",
    "class0Y = testY[class0Indices]\n",
    "class1Y = testY[indices1]\n",
    "class2Y = testY[indices2]\n",
    "\n",
    "testX = np.vstack((class0X, class1X, class2X))\n",
    "testY = np.hstack((class0Y, class1Y, class2Y))\n",
    "\n",
    "print testX.shape, testY.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier\n",
    "\n",
    "# Run the next cell only if you want to use a subset of the 17 features generated:\n",
    "8 Pansharpened (0-7)\n",
    "8 Haralick (8-15)\n",
    "1 NDBI (16)\n",
    "1 Edge Density (17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)\n",
    "\n",
    "# trainX = trainX[:,0:7]\n",
    "# testX = testX[:,0:7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "print np.sum(trainY == 0)\n",
    "print np.sum(trainY == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original source code: https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.064837 using {'n_estimators': 1000, 'learning_rate': 0.2}\n",
      "-0.064837 (0.040836) with: {'n_estimators': 1000, 'learning_rate': 0.2}\n",
      "-0.066358 (0.041438) with: {'n_estimators': 5000, 'learning_rate': 0.2}\n",
      "-0.066358 (0.041438) with: {'n_estimators': 6000, 'learning_rate': 0.2}\n",
      "-0.066358 (0.041438) with: {'n_estimators': 7000, 'learning_rate': 0.2}\n",
      "-0.066358 (0.041438) with: {'n_estimators': 10000, 'learning_rate': 0.2}\n",
      "-0.065081 (0.041926) with: {'n_estimators': 1000, 'learning_rate': 0.3}\n",
      "-0.065608 (0.041337) with: {'n_estimators': 5000, 'learning_rate': 0.3}\n",
      "-0.065608 (0.041338) with: {'n_estimators': 6000, 'learning_rate': 0.3}\n",
      "-0.065608 (0.041338) with: {'n_estimators': 7000, 'learning_rate': 0.3}\n",
      "-0.065608 (0.041338) with: {'n_estimators': 10000, 'learning_rate': 0.3}\n",
      "-0.069636 (0.044057) with: {'n_estimators': 1000, 'learning_rate': 0.5}\n",
      "-0.069566 (0.044096) with: {'n_estimators': 5000, 'learning_rate': 0.5}\n",
      "-0.069566 (0.044096) with: {'n_estimators': 6000, 'learning_rate': 0.5}\n",
      "-0.069566 (0.044097) with: {'n_estimators': 7000, 'learning_rate': 0.5}\n",
      "-0.069566 (0.044097) with: {'n_estimators': 10000, 'learning_rate': 0.5}\n",
      "-0.069781 (0.044145) with: {'n_estimators': 1000, 'learning_rate': 0.7}\n",
      "-0.069782 (0.044145) with: {'n_estimators': 5000, 'learning_rate': 0.7}\n",
      "-0.069782 (0.044145) with: {'n_estimators': 6000, 'learning_rate': 0.7}\n",
      "-0.069782 (0.044145) with: {'n_estimators': 7000, 'learning_rate': 0.7}\n",
      "-0.069782 (0.044145) with: {'n_estimators': 10000, 'learning_rate': 0.7}\n",
      "-0.070069 (0.041518) with: {'n_estimators': 1000, 'learning_rate': 0.9}\n",
      "-0.070069 (0.041518) with: {'n_estimators': 5000, 'learning_rate': 0.9}\n",
      "-0.070069 (0.041518) with: {'n_estimators': 6000, 'learning_rate': 0.9}\n",
      "-0.070069 (0.041518) with: {'n_estimators': 7000, 'learning_rate': 0.9}\n",
      "-0.070069 (0.041517) with: {'n_estimators': 10000, 'learning_rate': 0.9}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "xdata and ydata must be the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-46c5fde78496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f (%f) with: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"XGBoost learning_rate vs Log Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36merrorbar\u001b[0;34m(x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   2928\u001b[0m                           \u001b[0mxlolims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxlolims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxuplims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxuplims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                           \u001b[0merrorevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrorevery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapthick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapthick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2930\u001b[0;31m                           **kwargs)\n\u001b[0m\u001b[1;32m   2931\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36merrorbar\u001b[0;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m             \u001b[0mdata_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplot_line_style\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2904\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m         \u001b[0mbarcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1785\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \"\"\"\n\u001b[0;32m-> 1809\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \"\"\"\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda2/lib/python2.7/site-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xdata and ydata must be the same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: xdata and ydata must be the same length"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "model = xgboost.XGBClassifier(nthread=16 ,objective='binary:logistic')\n",
    "learning_rate = [0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "n_estimators = [1000,5000,6000, 7000, 10000]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators = n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "pyplot.errorbar(learning_rate, means, yerr=stds)\n",
    "pyplot.title(\"XGBoost learning_rate vs Log Loss\")\n",
    "pyplot.xlabel('learning_rate')\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.992366412214\n",
      "\n",
      "Confusion Matrix \n",
      " [[240   2]\n",
      " [  2 280]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.99      0.99      0.99       242\n",
      "      Other       0.99      0.99      0.99       282\n",
      "\n",
      "avg / total       0.99      0.99      0.99       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "#kfold = StratifiedKFold(n_splits = 10, random_state=7)\n",
    "xgb = xgboost.XGBClassifier(max_depth=500, n_estimators=1000, nthread=8 , objective='binary:logistic', learning_rate = 0.2 )\n",
    "#results = cross_val_score(xgb, trainX, trainY, cv=kfold)\n",
    "#print(results)\n",
    "xgb.fit(trainX,trainY)\n",
    "result = xgb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-xgboost-2-Cl-model.sav'\n",
    "pickle.dump(xgb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original source code: http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.050 (std: 0.017)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 500, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.050 (std: 0.017)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.050 (std: 0.017)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "#kfold = KFold(n_splits = 10, random_state=100)\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "#results = cross_val_score(rf,trainX, trainY, cv=kfold)\n",
    "#print results.mean(), results.std()\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [2, 3],\n",
    "              \"min_samples_leaf\": [1, 3],\n",
    "              \"n_estimators\": [500, 1000],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search = GridSearchCV(rf, param_grid = param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.988549618321\n",
      "\n",
      "Confusion Matrix \n",
      " [[240   2]\n",
      " [  4 278]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.98      0.99      0.99       242\n",
      "      Other       0.99      0.99      0.99       282\n",
      "\n",
      "avg / total       0.99      0.99      0.99       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, bootstrap = False, min_samples_leaf = 1, min_samples_split = 2, max_depth = None)\n",
    "rf.fit(trainX,trainY)\n",
    "result = rf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "fname = 'LS-rf-2-Cl-model.sav'\n",
    "pickle.dump(rf, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.967557251908\n",
      "\n",
      "Confusion Matrix \n",
      " [[240   2]\n",
      " [ 15 267]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.94      0.99      0.97       242\n",
      "      Other       0.99      0.95      0.97       282\n",
      "\n",
      "avg / total       0.97      0.97      0.97       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX,trainY)\n",
    "result = nb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-gnb-2-Cl-model.sav'\n",
    "pickle.dump(nb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.969465648855\n",
      "\n",
      "Confusion Matrix \n",
      " [[236   6]\n",
      " [ 10 272]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.96      0.98      0.97       242\n",
      "      Other       0.98      0.96      0.97       282\n",
      "\n",
      "avg / total       0.97      0.97      0.97       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(trainX,trainY)\n",
    "result = dt.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-dt-2-Cl-model.sav'\n",
    "pickle.dump(dt, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.917 (std: 0.099)\n",
      "Parameters: {'n_neighbors': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.917 (std: 0.097)\n",
      "Parameters: {'n_neighbors': 7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.916 (std: 0.100)\n",
      "Parameters: {'n_neighbors': 8}\n",
      "\n",
      "Overall accuracy = 0.965648854962\n",
      "\n",
      "Confusion Matrix \n",
      " [[242   0]\n",
      " [ 18 264]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.93      1.00      0.96       242\n",
      "      Other       1.00      0.94      0.97       282\n",
      "\n",
      "avg / total       0.97      0.97      0.97       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv = StratifiedKFold(n_splits = 10, random_state =7 )\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = list(np.arange(3,11,1))\n",
    "#print n_neighs\n",
    "params_grid = dict(n_neighbors= n_neighbors)\n",
    "knn_grid_search = GridSearchCV(estimator = knn, n_jobs = -1, param_grid = params_grid)\n",
    "knn_grid_result = knn_grid_search.fit(trainX, trainY)\n",
    "report(knn_grid_result.cv_results_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(trainX, trainY)\n",
    "result= knn.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-knn-2-Cl-model.sav'\n",
    "pickle.dump(knn, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "cv = StratifiedKFold(n_splits = 10, random_state =7 )\n",
    "Cs = np.logspace(-6, -1, 10)\n",
    "svmclf = SVC( kernel = 'poly')\n",
    "svm_grid_search = GridSearchCV(estimator = svmclf, param_grid = dict(C=Cs), n_jobs = -1)\n",
    "svm_grid_result = svm_grid_search.fit(trainX, trainY)\n",
    "report(svm_grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmclf = SVC(C=0.00016681005372000591)\n",
    "svmclf.fit(trainX, trainY)\n",
    "result = svmclf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Buildings','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.981 (std: 0.014)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'logistic', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.980 (std: 0.009)\n",
      "Parameters: {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.980 (std: 0.011)\n",
      "Parameters: {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.980 (std: 0.012)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'logistic', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100, 100, 100)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "params_grid={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100,100,100)],\n",
    "'alpha': [0.0001, 0.00001, 0.01],\n",
    "'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}\n",
    "\n",
    "mlp_grid_search = GridSearchCV(estimator=mlp,param_grid=params_grid,n_jobs=-1,cv=kfold)\n",
    "mlp_grid_result = mlp_grid_search.fit(trainX, trainY)\n",
    "report(mlp_grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.988549618321\n",
      "\n",
      "Confusion Matrix \n",
      " [[242   0]\n",
      " [  6 276]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.98      1.00      0.99       242\n",
      "      Other       1.00      0.98      0.99       282\n",
      "\n",
      "avg / total       0.99      0.99      0.99       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic', learning_rate = 'invscaling',hidden_layer_sizes=(100, 100, 100, 100), alpha = 0.00001)\n",
    "mlp.fit(trainX, trainY)\n",
    "result = mlp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-mlp-2-Cl-model.sav'\n",
    "pickle.dump(mlp, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "gp = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "gp.fit(trainX, trainY)\n",
    "result = gp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Slum','Urban','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.984 (std: 0.009)\n",
      "Parameters: {'n_estimators': 500, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.984 (std: 0.009)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.983 (std: 0.009)\n",
      "Parameters: {'n_estimators': 5000, 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.983 (std: 0.010)\n",
      "Parameters: {'n_estimators': 5000, 'learning_rate': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier()\n",
    "params_grid = dict(n_estimators=[50,100,500,1000,5000], learning_rate=[0.01, 0.007, 0.0001, 0.1, 0.0007])\n",
    "adb_grid_search = GridSearchCV(estimator=adb, param_grid = params_grid, cv=kfold)\n",
    "adb_search_result = adb_grid_search.fit(trainX, trainY)\n",
    "report(adb_search_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.988549618321\n",
      "\n",
      "Confusion Matrix \n",
      " [[241   1]\n",
      " [  5 277]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.98      1.00      0.99       242\n",
      "      Other       1.00      0.98      0.99       282\n",
      "\n",
      "avg / total       0.99      0.99      0.99       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb = AdaBoostClassifier(n_estimators=500, learning_rate=0.1)\n",
    "adb.fit(trainX, trainY)\n",
    "result = adb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-adaboost-2-Cl-model.sav'\n",
    "pickle.dump(adb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Implement majority voting using all the classifiers from above (with the properly tuned parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.996183206107\n",
      "\n",
      "Confusion Matrix \n",
      " [[242   0]\n",
      " [  2 280]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Building       0.99      1.00      1.00       242\n",
      "      Other       1.00      0.99      1.00       282\n",
      "\n",
      "avg / total       1.00      1.00      1.00       524\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [('xgb',xgb), ('rf',rf),('nb',nb), ('dt',dt), ('knn',knn), ('mlp',mlp), ('adb',adb)]\n",
    "vclf = VotingClassifier(estimators = estimators, n_jobs = -1)\n",
    "vclf.fit(trainX, trainY)\n",
    "result = vclf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Building','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'LS-majority-2-Cl-model.sav'\n",
    "pickle.dump(adb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3139, 3125, 36)\n",
      "(3139, 3125, 36)\n"
     ]
    }
   ],
   "source": [
    "# Now predict for the entire image\n",
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#rasterFileName = \"/home/gadiraju/data/bl-slums/raw-img/MUL_mosaic_415.tif\" #path to raster\n",
    "rasterFileName1 = \"/scratch/slums/bl-slums/raw-img/landsat7/PS-feb-2002-extract.tif\"\n",
    "dataset1 = gdal.Open(rasterFileName1)\n",
    "rasterFileName2 = \"/scratch/slums/bl-slums/raw-img/landsat7/ETM-feb-2002-extract-NDBI.tif\"\n",
    "dataset2 = gdal.Open(rasterFileName2)\n",
    "rasterFileName3 = \"/scratch/slums/bl-slums/raw-img/landsat7/simple-feb-2002-extract.tif\"\n",
    "dataset3 = gdal.Open(rasterFileName3)\n",
    "rasterFileName4 = \"/scratch/slums/bl-slums/raw-img/landsat7/adv-feb-2002-extract.tif\"\n",
    "dataset4 = gdal.Open(rasterFileName4)\n",
    "rasterFileName5 = \"/scratch/slums/bl-slums/raw-img/landsat7/higher-feb-2002-extract.tif\"\n",
    "dataset5 = gdal.Open(rasterFileName5)\n",
    "\n",
    "\n",
    "bands1=[]\n",
    "bands2=[]\n",
    "bands3=[]\n",
    "bands4=[]\n",
    "bands5=[]\n",
    "data_all_bands = []\n",
    "cols = dataset1.RasterXSize\n",
    "rows = dataset1.RasterYSize\n",
    "\n",
    "transform = dataset1.GetGeoTransform()\n",
    "\n",
    "\n",
    "img_data = np.zeros((rows, cols,36)) - 1\n",
    "print img_data.shape\n",
    "\n",
    "for i in range(6):\n",
    "    band = dataset1.GetRasterBand(i+1)\n",
    "    data = band.ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    img_data[:,:,i] = data\n",
    "    # data_all_bands.append(band.ReadAsArray(0,0,cols,rows).astype(np.float))\n",
    "band = dataset2.GetRasterBand(1)\n",
    "data = band.ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "img_data[:,:,6] = data\n",
    "for i in range(8):#simple\n",
    "    band = dataset3.GetRasterBand(i+1)\n",
    "    data = band.ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    img_data[:,:,7+i] = data\n",
    "for i in range(10):#adv\n",
    "    band = dataset4.GetRasterBand(i+1)\n",
    "    data = band.ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    img_data[:,:,15+i] = data\n",
    "for i in range(11):#higher\n",
    "    band = dataset5.GetRasterBand(i+1) \n",
    "    data = band.ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    img_data[:,:,25+i] = data\n",
    "\n",
    "print img_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osr\n",
    "\n",
    "def write_image(imgrows, imgcols, imgbands, imggeotrans,edges, opath):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(opath, imgrows, imgcols, imgbands, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform(imggeotrans)\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(edges)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(32643)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1000 rows\n",
      "Finished 2000 rows\n",
      "Finished 3000 rows\n"
     ]
    }
   ],
   "source": [
    "model = rf\n",
    "result_raster = np.zeros((rows, cols)) - 1\n",
    "for i in range(rows):\n",
    "    curr_row = img_data[i,:,:]\n",
    "    result_raster[i,:] = model.predict(curr_row)\n",
    "    if i%1000 == 0 and i > 0:\n",
    "        print 'Finished {} rows'.format(i)\n",
    "write_image(cols, rows, 1,transform, result_raster, '/scratch/slums/bl-slums/clf-img/LS-RF-Feb-2002.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4575472\n",
      "5233903\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print np.sum(result_raster == 0)\n",
    "print np.sum(result_raster == 1)\n",
    "print np.sum(result_raster> 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
