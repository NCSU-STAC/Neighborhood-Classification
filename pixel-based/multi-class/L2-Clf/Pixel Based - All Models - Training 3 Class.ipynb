{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/unity.ncsu.edu/users/k/kgadira/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3547, 18) (3547,) (779, 18) (779,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnTestSlums = np.sum(testY==0)\\n\\n# print nTestSlums\\n# Pick all other attributes in number equal to nTestSlums randomly\\nclass0Indices = np.where(testY==0)\\nclass1Indices = np.where(testY==1)\\nclass2Indices = np.where(testY==2)\\n\\nprint len(class1Indices[0])\\nindices1 = class1Indices[0][np.random.choice(len(class1Indices[0]), nTestSlums)]\\nindices2 = class2Indices[0][np.random.choice(len(class2Indices[0]), nTestSlums)]\\n\\nclass0X = testX[class0Indices[0],:]\\nclass1X = testX[indices1,:]\\nclass2X = testX[indices2,:]\\n\\nprint class0X.shape, class1X.shape, class2X.shape\\nclass0Y = testY[class0Indices]\\nclass1Y = testY[indices1]\\nclass2Y = testY[indices2]\\n\\ntestX = np.vstack((class0X, class1X, class2X))\\ntestY = np.hstack((class0Y, class1Y, class2Y))\\n\\nprint testX.shape, testY.shape\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import ogr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Read files \n",
    "trainX = np.load('/scratch/slums/bl-slums/gt/final-px-tr-3-Xa')\n",
    "trainY = np.load('/scratch/slums/bl-slums/gt/final-px-tr-3-Ya')\n",
    "testX = np.load('/scratch/slums/bl-slums/gt/final-px-te-3-Xa')\n",
    "testY = np.load('/scratch/slums/bl-slums/gt/final-px-te-3-Ya')\n",
    "\n",
    "trainY = trainY.ravel()\n",
    "testY = testY.ravel()\n",
    "print trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.494 (std: 0.039)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.569 (std: 0.035)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.639 (std: 0.044)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "model = xgboost.XGBClassifier(nthread=16 ,objective='multi:softmax')\n",
    "learning_rate = [0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "n_estimators = [1000,5000,6000, 7000, 10000]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators = n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.83055198973\n",
      "\n",
      "Confusion Matrix \n",
      " [[148  86   1]\n",
      " [ 38 164   0]\n",
      " [  1   6 335]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.79      0.63      0.70       235\n",
      "     Formal       0.64      0.81      0.72       202\n",
      "      Other       1.00      0.98      0.99       342\n",
      "\n",
      "avg / total       0.84      0.83      0.83       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "#kfold = StratifiedKFold(n_splits = 10, random_state=7)\n",
    "xgb = xgboost.XGBClassifier(max_depth=500, n_estimators=1000, nthread=8 , objective='multi:softmax', learning_rate = 0.2 )\n",
    "#results = cross_val_score(xgb, trainX, trainY, cv=kfold)\n",
    "#print(results)\n",
    "xgb.fit(trainX,trainY)\n",
    "result = xgb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-xgboost-3-Cl-model.sav'\n",
    "pickle.dump(xgb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782148.3121834793, 0.499284950117, 0.0, 1428678.0102606558, 0.0, -0.499231422086) \n",
      " +++++++++++++++++++++++++++ \n",
      " (782148.3121834793, 0.499284950117, 0.0, 1428678.0102606558, 0.0, -0.499231422086) \n",
      " (782148.3121834793, 0.499284950117, 0.0, 1428678.0102606558, 0.0, -0.499231422086)\n",
      "782148.312183 1428678.01026 0.499284950117 0.499231422086\n",
      "482 448\n",
      "115549 46071 54316\n"
     ]
    }
   ],
   "source": [
    "# Read the image samples created before\n",
    "from osgeo import gdal\n",
    "import ogr, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "ind = 3\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#rasterFileName = \"/home/gadiraju/data/bl-slums/raw-img/MUL_mosaic_415.tif\" #path to raster\n",
    "rasterFileName1 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_extract_{}.tif\".format(ind)\n",
    "dataset1 = gdal.Open(rasterFileName1)\n",
    "rasterFileName2 = \"/scratch/slums/bl-slums/raw-img/PS_mosaic_NDBI_extract_{}.tif\".format(ind)\n",
    "dataset2 = gdal.Open(rasterFileName2)\n",
    "rasterFileName3 = \"/scratch/slums/bl-slums/raw-img/PAN_mosaic_simple_extract_{}.tif\".format(ind)\n",
    "dataset3 = gdal.Open(rasterFileName3)\n",
    "rasterFileName4 = \"/scratch/slums/bl-slums/raw-img/PAN_mosaic_edgeDensity_{}.tif\".format(ind)\n",
    "dataset4 = gdal.Open(rasterFileName4)\n",
    "imggeotrans1 = dataset1.GetGeoTransform()\n",
    "coordinates_list = []\n",
    "\n",
    "bands1=[]\n",
    "bands2=[]\n",
    "bands3=[]\n",
    "bands4=[]\n",
    "data_all_bands = []\n",
    "cols = dataset1.RasterXSize\n",
    "rows = dataset1.RasterYSize\n",
    "\n",
    "transform = dataset1.GetGeoTransform()\n",
    "\n",
    "imggeotrans2 = dataset2.GetGeoTransform()\n",
    "imggeotrans3 = dataset3.GetGeoTransform()\n",
    "\n",
    "\n",
    "print '{} \\n +++++++++++++++++++++++++++ \\n {} \\n {}'.format(imggeotrans1, imggeotrans2, imggeotrans3)\n",
    "\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "\n",
    "print xOrigin, yOrigin, pixelWidth, pixelHeight\n",
    "\n",
    "for i in range(8):\n",
    "    bands1.append(dataset1.GetRasterBand(i+1)) \n",
    "    # data_all_bands.append(band.ReadAsArray(0,0,cols,rows).astype(np.float))\n",
    "bands2.append(dataset2.GetRasterBand(1))\n",
    "for i in range(8):\n",
    "    bands3.append(dataset3.GetRasterBand(i+1)) \n",
    "bands4.append(dataset4.GetRasterBand(1))\n",
    "\n",
    "curr_img = np.zeros((rows,cols,18))-1\n",
    "for k in range(8):\n",
    "    data = bands1[k].ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    curr_img[:,:,k] = data\n",
    "for k in range(8):\n",
    "    data = bands3[k].ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "    curr_img[:,:,8+k] = data \n",
    "data = bands2[0].ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "curr_img[:,:,16] = data\n",
    "data = bands4[0].ReadAsArray(0,0,cols,rows).astype(np.float)\n",
    "curr_img[:,:,17] = data\n",
    "print rows, cols\n",
    "result_raster = np.zeros((rows, cols))-1\n",
    "for i in range(curr_img.shape[0]):\n",
    "    curr_line = curr_img[i,:,:]\n",
    "    result_raster[i,:] = xgb.predict(curr_line)\n",
    "\n",
    "\n",
    "def write_image(imgrows, imgcols, imgbands, imggeotrans,edges, opath):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(opath, imgrows, imgcols, imgbands, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform(imggeotrans)\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(edges)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(32643)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "\n",
    "print np.sum(result_raster==0), np.sum(result_raster==1), np.sum(result_raster==2)\n",
    "\n",
    "write_image(cols, rows, 1, transform,result_raster, '/scratch/slums/bl-slums/clf-img/section-{}'.format(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.342 (std: 0.011)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.343 (std: 0.012)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 500, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.343 (std: 0.011)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 500, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [2, 3],\n",
    "              \"min_samples_leaf\": [1, 3],\n",
    "              \"n_estimators\": [500, 1000],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search = GridSearchCV(rf, param_grid = param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(trainX, trainY)\n",
    "report(grid_result.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.829268292683\n",
      "\n",
      "Confusion Matrix \n",
      " [[148  86   1]\n",
      " [ 35 166   1]\n",
      " [  1   9 332]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.80      0.63      0.71       235\n",
      "     Formal       0.64      0.82      0.72       202\n",
      "      Other       0.99      0.97      0.98       342\n",
      "\n",
      "avg / total       0.84      0.83      0.83       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, bootstrap = False, min_samples_leaf = 1, min_samples_split = 3, max_depth = None)\n",
    "rf.fit(trainX,trainY)\n",
    "result = rf.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "fname = 'VHR-rf-2-Cl-model.sav'\n",
    "pickle.dump(rf, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.771501925546\n",
      "\n",
      "Confusion Matrix \n",
      " [[208  24   3]\n",
      " [127  73   2]\n",
      " [  3  19 320]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.62      0.89      0.73       235\n",
      "     Formal       0.63      0.36      0.46       202\n",
      "         BG       0.98      0.94      0.96       342\n",
      "\n",
      "avg / total       0.78      0.77      0.76       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX,trainY)\n",
    "result = nb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','BG'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-gnb-3-Cl-model.sav'\n",
    "pickle.dump(nb, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.795892169448\n",
      "\n",
      "Confusion Matrix \n",
      " [[145  89   1]\n",
      " [ 51 150   1]\n",
      " [  4  13 325]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.72      0.62      0.67       235\n",
      "     Formal       0.60      0.74      0.66       202\n",
      "         BG       0.99      0.95      0.97       342\n",
      "\n",
      "avg / total       0.81      0.80      0.80       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(trainX,trainY)\n",
    "result = dt.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','BG'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-dt-3-Cl-model.sav'\n",
    "pickle.dump(dt, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.651 (std: 0.083)\n",
      "Parameters: {'n_neighbors': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.650 (std: 0.082)\n",
      "Parameters: {'n_neighbors': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.650 (std: 0.079)\n",
      "Parameters: {'n_neighbors': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.650 (std: 0.088)\n",
      "Parameters: {'n_neighbors': 6}\n",
      "\n",
      "Overall accuracy = 0.739409499358\n",
      "\n",
      "Confusion Matrix \n",
      " [[152  76   7]\n",
      " [102  90  10]\n",
      " [  1   7 334]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.60      0.65      0.62       235\n",
      "     Formal       0.52      0.45      0.48       202\n",
      "      Other       0.95      0.98      0.96       342\n",
      "\n",
      "avg / total       0.73      0.74      0.73       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv = StratifiedKFold(n_splits = 10, random_state =7 )\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = list(np.arange(3,11,1))\n",
    "#print n_neighs\n",
    "params_grid = dict(n_neighbors= n_neighbors)\n",
    "knn_grid_search = GridSearchCV(estimator = knn, n_jobs = -1, param_grid = params_grid)\n",
    "knn_grid_result = knn_grid_search.fit(trainX, trainY)\n",
    "report(knn_grid_result.cv_results_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(trainX, trainY)\n",
    "result= knn.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-knn-2-Cl-model.sav'\n",
    "pickle.dump(knn, open(fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.743 (std: 0.026)\n",
      "Parameters: {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.743 (std: 0.018)\n",
      "Parameters: {'alpha': 1e-05, 'activation': 'relu', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.739 (std: 0.022)\n",
      "Parameters: {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "params_grid={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100,100,100)],\n",
    "'alpha': [0.0001, 0.00001, 0.01],\n",
    "'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}\n",
    "\n",
    "mlp_grid_search = GridSearchCV(estimator=mlp,param_grid=params_grid,n_jobs=-1,cv=kfold)\n",
    "mlp_grid_result = mlp_grid_search.fit(trainX, trainY)\n",
    "report(mlp_grid_result.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.767650834403\n",
      "\n",
      "Confusion Matrix \n",
      " [[ 88 138   9]\n",
      " [ 24 170   8]\n",
      " [  0   2 340]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.79      0.37      0.51       235\n",
      "     Formal       0.55      0.84      0.66       202\n",
      "      Other       0.95      0.99      0.97       342\n",
      "\n",
      "avg / total       0.80      0.77      0.75       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='relu', learning_rate = 'constant',hidden_layer_sizes=(100, 100, 100, 100,100,100,100,100), alpha = 0.01)\n",
    "mlp.fit(trainX, trainY)\n",
    "result = mlp.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-mlp-3-Cl-model.sav'\n",
    "pickle.dump(mlp, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.749 (std: 0.017)\n",
      "Parameters: {'n_estimators': 1000, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.747 (std: 0.020)\n",
      "Parameters: {'n_estimators': 500, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.746 (std: 0.021)\n",
      "Parameters: {'n_estimators': 5000, 'learning_rate': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "adb = AdaBoostClassifier()\n",
    "params_grid = dict(n_estimators=[50,100,500,1000,5000], learning_rate=[0.01, 0.007, 0.0001, 0.1, 0.0007])\n",
    "adb_grid_search = GridSearchCV(estimator=adb, param_grid = params_grid, cv=kfold)\n",
    "adb_search_result = adb_grid_search.fit(trainX, trainY)\n",
    "report(adb_search_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.770218228498\n",
      "\n",
      "Confusion Matrix \n",
      " [[175  59   1]\n",
      " [107  95   0]\n",
      " [  0  12 330]]\n",
      "\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Informal       0.62      0.74      0.68       235\n",
      "     Formal       0.57      0.47      0.52       202\n",
      "      Other       1.00      0.96      0.98       342\n",
      "\n",
      "avg / total       0.77      0.77      0.77       779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "adb = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1)\n",
    "adb.fit(trainX, trainY)\n",
    "result = adb.predict(testX)\n",
    "acc = accuracy_score(testY, result)\n",
    "cm = confusion_matrix(testY, result)\n",
    "cr = classification_report(testY,result, target_names=['Informal','Formal','Other'])\n",
    "print 'Overall accuracy = {}\\n'.format(acc)\n",
    "#print 'Slum accuracy = {}\\n'.format(cm[0,0]/np.sum(cm[0,:]))\n",
    "print 'Confusion Matrix \\n {}\\n'.format(cm)\n",
    "print 'Classification Report \\n {}\\n'.format(cr)\n",
    "\n",
    "fname = 'VHR-adaboost-3-Cl-model.sav'\n",
    "pickle.dump(adb, open(fname, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
